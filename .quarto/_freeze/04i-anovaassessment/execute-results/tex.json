{
  "hash": "d3e9ae25eb67a6d7c15fcb1a3b035182",
  "result": {
    "engine": "knitr",
    "markdown": "# Assessing the Modeling Conditions in ANOVA {#sec-anovaassessment}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this unit we have discussed a model relating a quantitative response to a categorical predictor.  For the Organic Food Case Study, our model has had the form\n\n$$(\\text{Moral Expectations})_i = \\mu_1 (\\text{Comfort})_i + \\mu_2 (\\text{Control})_i + \\mu_3 (\\text{Organic})_i + \\varepsilon_i,$$\n\nwhere we use the same indicator variables defined in @sec-anovamodel.  Further, we considered three conditions on the distribution of the error term:\n\n  1.  The error in the moral expectation score for one individual is independent of the error in the moral expectation score for all other individuals.  \n  2.  The variability in the error for the moral expectation score within a group is the same for any food exposure group.\n  3.  The error in the moral expectation score follows a Normal distribution.\n  \nHowever, while we imposed all three of these conditions in @sec-anovateststat, we could have developed an empirical model for the null distribution of the standardized statistic only enforcing the first of these conditions on the distribution of the error.  Unfortunately, we cannot simply state conditions and then proceed blindly.  In order to rely on the p-values and confidence intervals produced from any modeling procedure, the data must be consistent with the conditions imposed.\n\nIn this section, we discuss how we assess these conditions qualitatively.  Just as we saw in @sec-regassessment, while the conditions are placed on the error terms, they are assessed using __residuals__.\n\n:::{.theorem.definition}\n\n\n\n\n\n## Residual\nThe difference between the observed response and the predicted response (estimated deterministic portion of the model). Specifically, the residual for the $i$-th observation is given by\n\n$$(\\text{Residual})_i = (\\text{Response})_i - (\\text{Predicted Mean Response})_i$$\n\nwhere the \"predicted mean response\" is often called the predicted, or fitted, value.\n\nResiduals mimic the noise in the data generating process.\n\n\n\n\n\n:::\n\nFor the ANOVA model, the predicted mean response is the observed sample mean of each group.  \n\n:::{.callout-tip}\n## Big Idea\nThe conditions are placed on the error term, but they are assessed with residuals.\n:::\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n## Assessing the Independence Condition\n  > The error in the moral expectation score for one individual is independent of the error in the moral expectation score for all other individuals.\n  \nGenerally, independence is assessed by considering the method in which the data was collected and considering the context with a discipline expert.  By carefully considering the manner in which the data was collected, we can typically determine whether it is reasonable that the errors in the response are independent of one another.  Some key things to consider when examining the data collection process:\n\n  - Are there repeated observations made on the same subject?  This often suggests some type of relationship between the responses and therefore would not be consistent with errors being independent.  In particular, look for blocking.\n  - Is the response measured over time (time-series) such as daily temperature over the course of a month?  Time-series data often exhibits strong period-to-period relationships suggesting the errors are not independent.  For example, if it is hot today, it will probably be hot tomorrow as well.\n  - Is there a learning curve in how the data was collected?  Learning curves again suggest some dependence from one observation to the next.  For example, a new nurse may become better at collecting pulse readings with more practice over time.\n  - Measurement devices which are failing over time will introduce a dependence from one observation to the next.  Imagine a bathroom scale that begins to add an additional pound each day.  Then, being above average weight one day will most likely lead to an above average weight the next, due primarily to the measurement device.\nGenerally, independence is assessed through the context of the data collection scheme.  By carefully considering the manner in which the data was collected, we can typically determine whether it is reasonable that the errors in the response are independent of one another.  Some key things to consider when examining the data collection process:\n  \nThese last three points illustrate a particular deviation from our condition of independence in which two observations collected close together in time are related.  When we know the order in which the data was collected, we can assess whether the data tends to deviate from the condition of independence in this manner.  This is done graphically through a __time-series plot__ of the _residuals_.  If two errors were unrelated, then the value of one residual should tell us nothing about the value of the next residual.  Therefore, a plot of the residuals over time should look like noise (since residuals are supposed to mimic the noise in the model).  If there are any trends, then it suggests the data is not consistent with independence.\n\n:::{.theorem.definition}\n\n\n\n\n\n## Time-Series Plot\nA time-series plot of a variable is a line plot with the variable on the y-axis and time on the x-axis.\n\n\n\n\n\n:::\n\n:::{.callout-note}\n## Graphically Assessing the Independence Condition\nIf the data is consistent with the independence condition, we would not expect to see a trend in the _location_ or _spread_ in a time-series plot of the residuals.  Note that this graphic can only be used if the order in which the data was collected is known, and the order indicates some natural timing.\n:::\n\nFor the Organic Food Case Study, participants were assessed simultaneously within a large lecture.  Therefore, there is no ordering in time to be concerned about, and a time-series plot of the residuals would not be useful here.  Since we cannot rely on a graphic, we can only rely on what we know about how the data was collected.  Students worked individually on the questionnaire; there was nothing in the data description of how the data was collected that would lead us to believe that one student's response would be impacted by any other student's response.  And, no blocking was implemented.  Our review of the data collection methods suggests it is reasonable to assume that the errors in the moral expectation score are unrelated to one another.  \n\n\n## Assessing Homoskedasticity\n  > The variability of the error in the moral expectation within each food exposure group is the same across all food exposure groups.\n  \nWe want the variability in the errors within a group to be the same across the groups.  We can do this by examining side-by-side boxplots (or jitter plots, etc.) of the residuals within each of the groups. @fig-anovaassessment-variance-organic shows the residuals for each individual across the various groups.  Notice that the boxes for each group are roughly the same size; that is, the interquartile ranges are similar.  This suggests that the variability within each group is similar from one group to the next.  That is, the data is consistent with the constant variance condition.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of the residuals predicting the moral expectation score for college students exposed to different types of food.](./images/fig-anovaassessment-variance-organic-1.pdf){#fig-anovaassessment-variance-organic fig-alt='Boxplot of residuals for each food exposure group showing similar spread across the groups.' width=80%}\n:::\n:::\n\n\n\n\n\n\nThere is a second (equivalent) approach to assessing this condition.  From the model for the data generating process, we see that the response for any individual is some constant plus noise; therefore, the distribution of the responses for any group is simply a shifted version of the distribution of the errors within the same group.  If the variability in the errors for each response is the same, then the variability of the response must be the same for each group.  Therefore, we can also examine the side-by-side boxplots (or jitter plots, etc.) of the response instead of the residuals.  @fig-anovaassessment-variance-organic-alt shows the moral expectation score for each individual across the various groups.  Just as in the previous graphic, the interquartile ranges are similar for each of the three groups indicating the data is consistent with this condition.  The benefit of the first approach is that the residuals will always be centered around 0 within each group; this allows for easy side-by-side comparisons; when looking at the observed response, the data need not be aligned across the groups.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of the moral expectation scores for college students exposed to different types of food.](./images/fig-anovaassessment-variance-organic-alt-1.pdf){#fig-anovaassessment-variance-organic-alt fig-alt='Boxplot of moral expectation scores for each food exposure group showing similar spread across the groups.' width=80%}\n:::\n:::\n\n\n\n\n\n\nFinally, there is a third (equivalent) approach to assessing this condition --- assessing it just as we did for linear regression models.  We can create a plot of the residuals against the fitted values.  @fig-anovaassessment-variance-organic-alt2 shows the residuals plotted against the fitted values.  Just as in the previous graphic, the interquartile ranges are similar for each of the three groups indicating the data is consistent with this condition.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Residuals plotted against the predicted the moral expectation scores for college students exposed to different types of food.](./images/fig-anovaassessment-variance-organic-alt2-1.pdf){#fig-anovaassessment-variance-organic-alt2 fig-alt='Scatterplot of residuals against the fitted values.' width=80%}\n:::\n:::\n\n\n\n\n\n\nThis does not have the same pattern as what we might have expected from @sec-regassessment.  Remember, our study only had three groups; therefore, the deterministic portion of the model for the data generating process is only comparing three groups, and as a result, it can only predict one of three values for the average response.  Each vertical \"slice\" in @fig-anovaassessment-variance-organic-alt2 represents the residuals from one of those three predicted responses.  \n\n:::{.callout-warning}\nThe order of the groups when plotting the response against the groups need not be the same as the order when plotting the residuals against the fitted values.\n:::\n\n:::{.callout-warning}\nWhen plotting the residuals against the fitted values in ANOVA, if two groups are similar, but these differ from the other groups, the vertical \"slices\" can be nearly on top of one another, making it difficult to assess the constant variance condition.  It is for this reason we prefer one of the first two methods discussed in this section.\n:::\n\n:::{.callout-note}\n## Graphically Assessing the Constant Variance Condition\nIf the data is consistent with the constant variance condition, there should be no trends in the _spread_ of the residuals (or the response) across each group.\n:::\n\n\n## Assessing Normality\n  > The errors in the moral expectation score follows a Normal distribution.\n\nIf the errors follow a Normal distribution, then we would expect the residuals to mimic a sample taken from a Normal distribution.  As introduced in @sec-regassessment, we emphasize the Normal __probability plot__ for assessing the Normality condition.\n\n:::{.theorem.definition}\n\n\n\n\n\n## Probability Plot\nAlso called a \"Quantile-Quantile Plot\", a probability plot is a graphic for comparing the distribution of an observed sample with a theoretical probability model for the distribution of the underlying population.  The quantiles observed in the sample are plotted against those expected under the theoretical model.\n\n\n\n\n\n:::\n\n:::{.callout-note}\n## Graphically Assessing the Normality Condition\nIf the data is consistent with the normality condition, the Normal probability plot of the residuals should exhibit a straight line with any deviations appearing to be random.  Systemic deviations from a straight line indicate the observed distribution does not align with the proposed model.\n:::\n\n@fig-anovaassessment-normal-organic shows the probability plot for the residuals from the Organic Food Case Study.\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Normal probability plot of the residuals for the Organic Food Case Study.](./images/fig-anovaassessment-normal-organic-1.pdf){#fig-anovaassessment-normal-organic fig-alt='Plot of the sample quantiles against the theoretical quantiles exhibiting a straight line.' width=80%}\n:::\n:::\n\n\n\n\n\n\nOverall, the points do tend to follow a straight line.  There are some deviations from a linear relationship at each end of the plot, but the deviations are not extreme and do not appear to be systematic.  Deviations in the tails are common, especially with larger datasets.  And with naturally less data in the tails, it can become more difficult to establish a pattern.  We are generally not concerned unless these tails form a part of a larger pattern of deviating from the linear trend.  We believe these residuals are consistent with the errors having a Normal distribution.\n\n\n## General Tips for Assessing Assumptions\nFirst discussed in @sec-regassessment, we want to remember four things that should be kept in mind when assessing conditions:\n\n  1. We should not spend an extraordinary amount of time examining any one residual plot; we might convince ourselves of patterns that do not exist.  We are looking for major deviations from our expectations.\n  2. We can never prove a condition is satisfied; we can only determine whether the data is consistent with a condition or whether it is not consistent with a condition.\n  3. Any condition required for a particular analysis should be assessed.\n  4. Transparency is crucial.\n",
    "supporting": [
      "04i-anovaassessment_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}