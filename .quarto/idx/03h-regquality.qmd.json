{"title":"Quantifying the Quality of a Model Fit","markdown":{"headingText":"Quantifying the Quality of a Model Fit","headingAttr":{"id":"sec-regquality","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n{{< include _setupcode.qmd >}}\n\nIn the previous two chapters, we described a model for describing the data generating process for a quantitative response as a function of a single quantitative predictor:\n\n$$(\\text{Response})_i = \\beta_0 + \\beta_1 (\\text{Predictor})_i + \\varepsilon_i$$\n\n@sec-regmodel discussed obtaining estimates of these unknown parameters using the method of least squares.  @sec-regconditions imposed conditions on the stochastic portion of the model in order to develop a confidence interval for each parameter.  In this chapter, we turn to performing inference through the computation of a p-value for a set of hypotheses, and we discuss how to quantify the quality of our model with regard to its utility in making predictions.  It turns out these two tasks are very much related and are accomplished through partitioning variability.  We will describe what we mean by partitioning variability and how it is used to derive a measure for the overall performance of a model and to develop a standardized statistic for comparing two models.  As with previous discussions, these ideas will form another thread of the story that continues throughout the text.\n\n\n## Partitioning Variability\nLet's return to the Seismic Activity Case Study first introduced in @sec-casegreece.  Consider modeling the bracketed duration at a location as a function of the distance the location is from the center of the earthquake using the following model for the data generating process:\n\n$$(\\text{Bracketed Duration})_i = \\beta_0 + \\beta_1(\\text{Epicentral Distance})_i + \\varepsilon_i.$$\n\nUsing least squares to estimate the parameters, and assuming the data is consistent with the conditions for the classical regression model, the resulting model fit is summarized below in @tbl-regquality-fit.\n\n```{r}\n#| label: tbl-regquality-fit\n#| tbl-cap: Summary of the model fit explaining the bracketed duration as a function of epicentral distance.\n\nfit.greece.slr2 <- lm(BD02 ~ Epicentral_Distance, data = greece.df)\n\nfit.greece.slr2 |>\n  estimate_parameters(confidence.level = 0.95,\n                      assume.constant.variance = TRUE,\n                      assume.normality = TRUE) |>\n  rename(Term = term,\n         Estimate = point.estimate,\n         `Standard Error` = standard.error,\n         `Lower 95% CI` = `95% lower`,\n         `Upper 95% CI` = `95% upper`) |>\n  mutate(Term = recode(Term, \n                       \"Epicentral_Distance\" = \"Epicentral Distance\")) %>%\n  mykable(digits = 3)\n```\n\nRemember, the goal of the model for the data generating process is to explain why the response is the value we see --- we are essentially explaining why the values of the response differ from one individual unit to another (the variability in the response).  Consider the model for the data generating process summarized above; it includes two reasons why the bracketed duration is not the same value at each measured location:\n\n  - The locations at which the observations are taken are different distances from the epicenter of each earthquake.\n  - Additional noise due to measurement error in the bracketed duration or additional natural sources we are unable to explain or did not account for in the model.\n  \nLooking at the form of the model for the data generating process, it may seem obvious that there are these two sources of variability --- two sources for why the bracketed duration differs from one individual observation to another.  Our next endeavor is to quantify the amount of variability in the response that can be attributed to each of these components.  That is, we move forward with a goal of trying to say something like\n\n$$\\begin{pmatrix} \\text{Total Variability} \\\\ \\text{in the Bracketed Duration} \\end{pmatrix} = \\begin{pmatrix} \\text{Variability due} \\\\ \\text{to Distance} \\end{pmatrix} + \\begin{pmatrix} \\text{Variability due} \\\\ \\text{to Noise} \\end{pmatrix}$$\n\nAs we have seen in both @sec-summaries and @sec-teststat, variability can be quantified through considering the \"total\" distance the observations are from a common target (for example, the mean response) where \"distance\" is captured by squared deviations.  That is, the total variability in bracketed duration can be measured by\n\n$$\\sum_{i=1}^{n} \\left[(\\text{Bracketed Duration})_i - (\\text{Overall Mean Bracketed Duration})\\right]^2.$$ {#eq-regquality-sst}\n\nNotice this quantity is related to, but not equivalent to, the sample variance.  It measures the distance each response is from the sample mean and then adds these distances up.  This is known as the __Total Sum of Squares__ since it captures the total variability in the response.\n\n:::{#def-sst}\n## Total Sum of Squares\nThe Total Sum of Squares, abbreviated SST, is given by\n\n$$SST = \\sum_{i=1}^{n} \\left[(\\text{Response})_i - (\\text{Overall Average Response})_i\\right]^2$$\n\nwhere the overall average response is the sample mean.\n:::\n\nWe now have a way of quantifying the total variability in the bracketed duration; we now want to partition (or separate) out this variability into its two components: the variability due to the epicentral distance, and the variability due to noise.  In order to capture the variability due epicentral distance, we consider how epicentral distance plays a role in the model for the data generating process: it forms the line which dictates the mean response.  That is, the linear portion in the model for the data generating process $\\beta_0 + \\beta_1 (\\text{Epicentral Distance})$ is the model's attempt to explain how changes in the epicentral distance explain changes in the bracketed duration; further, this explanation comes in the form of the average response.  That is, plugging into the deterministic portion of the model for the data generating process provides a mean response, and if we use the least squares estimates in place of the parameters, we are computing an estimate of the mean response.  Finding the variability in the bracketed duration due to the epicentral distance is then equivalent to finding the variability in these estimated (or predicted) mean responses:\n\n$$\\sum_{i=1}^{n} \\left[(\\text{Predicted Bracketed Duration})_i - (\\text{Overall Mean Bracketed Duration})\\right]^2.$$ {#eq-regquality-ssr}\n\nThis is known as the __Regression Sum of Squares__ as it captures the variability explained by the regression line.\n\n:::{#def-ssr}\n## Regression Sum of Squares\nThe Regression Sum of Squares, abbreviated SSR, is given by\n\n$$SSR = \\sum_{i=1}^{n} \\left[(\\text{Predicted Mean Response})_i - (\\text{Overall Mean Response})\\right]^2$$\n\nwhere the predicted mean response is computed using the least squares estimates and the overall mean response is the sample mean.\n:::\n\nFinally, the unexplained noise, $\\varepsilon$ in our model for the data generating process, is the difference between the actual response and the deterministic portion of the model (in our case, the true regression line).  This variability in the noise is then the variability in the bracketed duration where the average is _conditional_ on the epicentral distance instead of ignoring it (which is what happens when we use the overall sample mean bracketed duration):\n\n$$\\sum_{i=1}^{n} \\left[(\\text{Bracketed Duration})_i - (\\text{Predicted Bracketed Duration})_i\\right]^2.$$ {#eq-regquality-sse}\n\nThis is known as the __Error Sum of Squares__ as it captures the variability not explained by the model but represented by the error term in the model.\n\n:::{#def-sse}\n## Error Sum of Squares\nThe Error Sum of Squares, abbreviated SSE and sometimes referred to as the Residual Sum of Squares, is given by\n\n$$SSE = \\sum_{i=1}^{n} \\left[(\\text{Response})_i - (\\text{Predicted Mean Response})_i\\right]^2$$\n\nwhere the predicted mean response is computed using the least squares estimates.\n:::\n\nWith some clever algebra, it can be easily seen that the total variability does in fact partition into these two components.  This discussion is represented in @fig-regquality-partition-variability.\n\n:::{.callout-tip}\n## Big Idea\nThe total variability in a response can be partitioned into two components: the variability explained by the predictor and the unexplained variability left in the error term.  This is represented in the formula\n\n$$SST = SSR + SSE$$\n:::\n\n```{r}\n#| label: fig-regquality-partition-variability\n#| fig-cap: Illustration of partitioning the variability of a response using a regression model.\n#| fig-alt: Scatterplot of hypothetical data with a best fit line overlayed; for one of the points, the distance the point is from the overall average response is decomposed to illustrate the components that feed into the regression and error sums of squares.\nknitr::include_graphics(\"./images/RegQuality-Partitioning-Variability.jpg\")\n```\n\n\n## R-squared\nThe key to quantifying the quality of a model for the data generating process is to understand that a partition breaks a whole into smaller, distinct components.  This means that if you put the components back together, you have the whole.  The sums of squares partition the variability in the response into that explained by the deterministic portion of the model for the data generating process and that not explained.  We represented this above by the equation\n\n$$SST = SSR + SSE$$.\n\nThe benefit partitioning variability is that it makes clear the breakdown between the variability in the response that the deterministic portion of the model is explaining (SSR) versus the variability in the response that cannot be explained (SSE).  We are now in a position to quantify the proportion of the total variability the model is explaining, which is known as the __R-squared__ value for the model.\n\n:::{#def-r-squared}\n## R-Squared\nSometimes reported as a percentage, the R-Squared value measures the proportion of the variability in the response explained by a model.  It is given by \n\n$$\\text{R-squared} = \\frac{SSR}{SST}.$$\n:::\n\nFor our model of the bracketed duration as a function of the epicentral distance, the R-squared value turns out to be 0.0216; that is, only 2.16% of the variability in the bracketed duration at a location is explained by its distance from the center of the corresponding earthquake.\n\nAs R-squared is a proportion, it must take a value between 0 and 1.  If 0, that means our model has no predictive ability within our sample.  That is, knowing the predictor does not add to our ability to predict the response any more than guessing.  A value of 1 indicates that our model has predicted all the variability in the response; that is, given the predictor, we can perfectly predict the value of the response.\n\nIt may appear that obtaining an R-squared value of 1 should be our goal.  And, in one sense, it is.  We want a model that has strong predictive ability.  However, there is a danger in obtaining an R-squared of 1 as well.  We must remember that variability is inherent in any process.  Therefore, we should never expect to fully explain all the variability in a response.  George Box (a renowned statistician) once made the following statement [@Box1979]:\n\n  > \"Now it would be very remarkable if any system existing in the real world could be exactly represented by any simple model. However, cunningly chosen parsimonious models often do provide remarkably useful approximations. For example, the law $PV = RT$ relating pressure $P$, volume $V$ and temperature $T$ of an 'ideal' gas via a constant $R$ is not exactly true for any real gas, but it frequently provides a useful approximation and furthermore its structure is informative since it springs from a physical view of the behavior of gas molecules.  \n  >  \n  >  For such a model there is no need to ask the question 'Is the model true?'. If 'truth' is to be the 'whole truth' the answer must be 'No.' The only question of interest is 'Is the model illuminating and useful?'.\n\nThe idea here is that we know the model will not capture the data generating process precisely.  Therefore, we should be skeptical of models which claim to be perfect.  For example, consider the two models illustrated in @fig-regquality-overfit.  The model represented by the black line has a perfect fit, but we argue the model represented by the blue line is better.  While the black line captures all the variability in the response for this sample, it is certainly trying to do too much.  In reality, the blue line captures the underlying relationship while not overcomplicating that relationship.  We sacrifice a little quality in the fit for _this sample_ in order to better represent the underlying structure of _the population_.  The black line suffers from what is known as _overfitting_; the blue line is a more _parsimonious_ (simple) model, balancing complexity with model fit.\n\n```{r}\n#| label: fig-regquality-overfit\n#| fig-cap: Illustration of a parsimonious model compared to one which overfits the data.\n#| fig-alt: Scatterplot of hypothetical data with two models overlayed; a model represented by a black line connects all the points and has an R-squared of 1, and a model represented by a blue line captures the trend and has an R-squared of 0.94.\nset.seed(201708)\nplot.dat <- tibble(\n  x = seq(10),\n  y = 5 + x + rnorm(10)\n)\n\nggplot(data = plot.dat,\n       mapping = aes(x = x, y = y)) +\n  geom_line(linewidth = 1.1) +\n  geom_point(size = 6) +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE, \n              colour = \"blue\", linewidth = 1.1) +\n  labs(x = \"Predictor\", y = \"Response\") +\n  annotate(\"segment\", x = 1.75, xend = 2.4, y = 14, yend = 14, \n           colour = \"black\", linewidth = 1.1) +\n  annotate(\"segment\", x = 1.75, xend = 2.4, y = 13, yend = 13,\n           colour = \"blue\", linewidth = 1.1) +\n  annotate(\"label\", x = 2.5, y = 14, label = \"R^2 == 1\", \n           parse = TRUE, hjust = \"left\") +\n  annotate(\"label\", x = 2.5, y = 13, label = \"R^2 == 0.94\",\n           parse = TRUE, hjust = \"left\") +\n theme(axis.text = element_blank(),\n       axis.ticks = element_blank())\n```\n\nStudents often ask, \"if not 1, how high of an R-squared represents a _good_ model?\"  The answer depends a lot on the discipline.  In many engineering applications within a lab setting, we can control much of the external variability leading to extremely high R-squared values (0.95 to 0.99).  However, in biological applications, the variability among the population can be quite large, leading to much smaller R-squared values (0.3 to 0.6).  What is considered \"good\" can depend on the specific application.\n\n:::{.callout-warning}\nWhile R-squared is useful for quantifying the quality of a model on a set of data, it should not be used to compare two different models as R-squared always favors more complex models.  There are better methods which adjust for the complexity of the model fit.\n:::\n\nIn addition to the discipline, how you view the R-squared value for a model may depend on the goal of the model.  There are generally two broad reasons for developing a statistical model:\n\n  - Explain the relationship between a response and one or more predictors.  This can involve examining the marginal relationship, isolating the effect, or examining the interplay between predictors.  \n  - Predict a future response given a specific value for the predictors.  \n  \nIf all we are interested in doing is explaining the relationship, we may not be concerned about the predictive ability of the model.  That is, since our goal is not to accurately predict a future response, we are primary concerned with whether we have evidence of a relationship.  But, if our goal is prediction, we would like that estimate to be precise.  In such cases, a high R-squared is required before really relying on the model we have.\n\nWhat is perhaps counter-intuitive is that, while related, hypothesis testing and the R-squared value may not necessarily yield the same conclusions.  That is, it is possible that we have a strong evidence that the average response depends on the predictor (small p-value) _and_ simultaneously conclude that using the predictor would not result in precise predictions (low R-squared value).  \n\n\n## Hypothesis Testing\nIn addition to quantifying the quality of the model, partitioning the variability in a response into two components is the basis for conducting a hypothesis test to compare two models.  In this section, we expand upon the ideas initially presented in @sec-teststat, broadening them to add to our unifying framework.  Recall that hypothesis testing is really about comparing two models for the data generating process: a more complex model in which the parameters are free to take on any value, and a restricted model in which the parameters are constrained in some way.  \n\nWhen the sample does not provide enough evidence to suggest the more complex model is necessary to explain the variability in the response, we conclude it is reasonable the reduced model for the data generating process is appropriate (some say, we \"fail to reject\" the null hypothesis).  When the sample does provide sufficient evidence to suggest we can discern the difference in the performance of the reduced and complex model, we say the simple model is not sufficient for explaining the variability in the response, and we prefer the more complex model (some say, we \"reject\" the null hypothesis).  Throughout the remainder of this section, we will consider the following research question:\n\n  > Is there evidence the average bracketed duration for a location following an earthquake is linearly related to the distance the location is from the center of the earthquake?\n  \nIf we consider the simple linear model for the data generating process described above, this question can be captured using the following set of hypotheses:\n\n$$H_0: \\beta_1 = 0 \\qquad \\text{vs.} \\qquad H_1: \\beta_1 \\neq 0.$$\n\nAgain, hypothesis testing is really model comparison; that is, these hypotheses are really suggesting two separate models for the data generating process:\n\n$$\n\\begin{aligned}\n  \\text{Model 1}:& \\quad (\\text{Bracketed Duration})_i = \\beta_0 + \\beta_1 (\\text{Epicentral Distance})_i + \\varepsilon_i \\\\\n  \\text{Model 0}:& \\quad (\\text{Bracketed Duration})_i = \\beta_0 + \\varepsilon_i.\n\\end{aligned}\n$$\n\nThe model under the null hypothesis (Model 0) has fewer parameters because it is a constrained version of Model 1 resulting from setting $\\beta_1 = 0$.  In fact, while Model 1 says that there are two components (the epicentral distance and noise) contributing to the variability observed in the bracketed duration, Model 0 says that there is only a single component (noise).  So, we can think of our hypotheses as\n\n$$\n\\begin{aligned}\n  H_0: \\text{Model 0 is sufficient for explaining the variability in the response} \\\\\n  H_1: \\text{Model 0 is not sufficient for explaining the variability in the response.}\n\\end{aligned}\n$$\n\nRegardless of which model we choose, the total variability in the response remains the same.  We are simply asking whether the variability explained by the predictor is sufficiently large for us to say it has an impact.  In particular, if the null hypothesis were true, we would expect all the variability in the response to be channeled into the noise ($SST \\approx SSE$).  In fact, think about computing the error sum of squares for Model 0 above; it would be\n\n$$SSE_0 = \\sum_{i=1}^{n} \\left[(\\text{Bracketed Duration})_i - (\\text{Overall Average Bracketed Duration})\\right]^2$$\n\nsince the least squares estimate of $\\widehat{\\beta}_0$ in Model 0 is the sample mean (see @sec-app-teststat).  But, this is equivalent to the total sum of squares for Model 1 (@eq-regquality-sst).  This confirms our intuition that if the null hypothesis were true, we would expect all the variability in the response to be channeled into the noise ($SST \\approx SSE$).\n\nIf, however, the alternative hypothesis is true and the epicentral distance explains some portion of the variability in the bracketed duration, then we would expect some of the variability to be channeled out of the noise term ($SSR > 0$).  Because we have partitioned the variability, we now take a moment to recognize that\n\n$$SSR = SST - SSE,$$\n\nbut we know that the total sum of squares is just the error sum of squares from the reduced model (Model 0) as shown above.  Therefore, we can write\n\n$$SSR = SSE_0 - SSE_1,$$ {#eq-regquality-ssr-difference}\n\nwhere we use the subscripts to denote whether we are discussing the error sum of squares from the reduced model (Model 0) or the full unconstrained model (Model 1).  That is, @eq-regquality-ssr-difference reveals that the regression sum of squares is the equivalent of the shift in the error sum of squares as we move from the reduced model under the null hypothesis to the more complex model under the alternative hypothesis.\n\n:::{.callout-tip}\n## Big Idea\nFor a particular dataset, the regression sum of squares quantifies the shift in the error sum of squares as we move from a reduced model to a more complex model.  It measures the \"signal\" in the data represented by the more complex model for the data generating process.\n:::\n\nThe regression sum of squares represents our signal.  The larger the value, the more evidence we have that the data is not consistent with the null hypothesis.  However, as we saw in @sec-teststat, we should always examine our signal relative to the noise in the data.  We already have a measure for the amount of variability due to noise --- the error sum of squares!  It then seems reasonable to consider the ratio \n\n$$\\frac{SSR}{SSE_1} = \\frac{SST - SSE_1}{SSE_1} = \\frac{SSE_0 - SSE_1}{SSE_1},$$\n\nwhere again we have added subscripts to emphasize from which model we are computing the sums of squares.  While this is a reasonable statistic, it is not yet standardized.  Remember that sums of squares capture variability but are themselves not variances, and it turns out a ratio of variances is easier to model analytically.  If we take a sum of squares and divide by an appropriate term, known as the __degrees of freedom__, we get a true variance term.\n\n:::{#def-df}\n## Degrees of Freedom\nA measure of the flexibility in a sum of squares term; when a sum of squares is divided by the corresponding degrees of freedom, the result is a variance term.\n:::\n\n:::{.callout-note}\n## Rationale for Degrees of Freedom\nDegrees of freedom are a very difficult concept to grasp, even for those who have been studying statistics for a while.  Here is our way of thinking about them --- they are the difference of available terms to work with.  For example, think about the total sum of squares associated with a full unconstrained linear regression model described in @eq-slr:\n  \n$$SST = \\sum_{i=1}^{n} \\left[(\\text{Response})_i - (\\text{Overall Average Response})\\right]^2.$$\n  \nThe first term of the difference has $n$ different values (one response for each observation).  However, the sample mean is just one value.  Therefore, there are $n - 1$ degrees of freedom associated with the total sum of squares.  This is often described as starting out with $n$ estimates (the data), but needing to estimate one parameter (the mean) along the way, leading to $n - 1$.\n\nSimilarly, consider the regression sum of squares for the full unconstrained model:\n\n$$SSR = \\sum_{i=1}^{n} \\left[(\\text{Predicted Mean Response})_i - (\\text{Overall Average Response})\\right]^2.$$\n  \nWhile there are $n$ predicted values, they are all generated from the same least squares fit $\\widehat{\\beta}_0 + \\widehat{\\beta}_1 (\\text{Predictor})_i$ which can be computed from two estimates (that for the intercept and slope).  Therefore, we begin with only 2 unique values.  Again, the sample mean has just one value, leading to $2 - 1 = 1$ degree of freedom associated with the regression sum of squares.\n\nFinally, consider the error sum of squares for the full unconstrained model:\n  \n$$SSE = \\sum_{i=1}^{n} \\left[(\\text{Response})_i - (\\text{Predicted Mean Response})_i\\right]^2.$$\n  \nWe have $n$ initial values (one for each observation).  However, as described above, we only need 2 terms to estimate the predicted values.  So, we have $n - 2$ degrees of freedom associated with the error sum of squares.\n\nNote that just as the sums of squares formed a partition ($SST = SSR + SSE$), the corresponding degrees of freedom form a partition ($(n - 1) = (2 - 1) + (n - 2)$).\n:::\n\nAgain, dividing a sum of squares by its associated degrees of freedom creates a variance term; this term is known as a __mean square__.  It is important to note that both sums of squares and mean squares quantify the components of variability in the response, the component explained by the deterministic portion of the model and the component that is unexplained.  However, they serve different purposes.  \n\n:::{#def-ms}\n## Mean Square\nA mean square is the ratio of a sum of squares and its corresponding degrees of freedom.  For a model of the form in @eq-slr, we have\n\n  - __Mean Square Total (MST)__: estimated variance of the responses; this is the same as the sample variance of the response.\n  - __Mean Square for Regression (MSR)__: estimated variance of the predicted responses.\n  - __Mean Square Error (MSE)__: estimated variance of the error terms; this is equivalent to the estimated variance of the response for a given value of the predictor (the variance of the response about the regression line).\n  \nIn each case, the mean square is an estimated variance.\n:::\n\n:::{.callout-note}\nSums of squares partition the variability of the response into smaller components; mean squares estimate the variance of those smaller components.  While $SST = SSR + SSE$, note that $MST \\neq MSR + MSE$.\n:::\n\nSince mean squares are proportional to their corresponding sum of squares, an increase in the sum of squares is associated with an increase in the corresponding mean square.  We are now ready to define our standardized statistic as the ratio of mean squares.  Instead of the ratio\n\n$$\\frac{SSR}{SSE_1} = \\frac{SST - SSE_1}{SSE_1} = \\frac{SSE_0 - SSE_1}{SSE_1},$$\n\nwe replace the numerator and denominator with mean squares such that\n\n$$\\frac{MSR}{MSE} = \\frac{\\left(SST - SSE_1\\right)/(2 - 1)}{SSE_1/(n - 2)} = \\frac{\\left(SSE_0 - SSE_1\\right)/(2 - 1)}{SSE_1/(n - 2)},$$\n\nwhere again we have added subscripts to emphasize from which model we are computing the sums of squares.  This standardized statistic could be used to quantify the signal-to-noise ratio (the amount of evidence) in the sample for testing the hypotheses\n\n  > $H_0: \\beta_1 = 0$  \n  > $H_1: \\beta_1 \\neq 0.$\n  \nHowever, we can generalize this for testing a range of hypotheses within our model for the data generating process.\n\n:::{#def-standard-f}\n## Standardized Statistic for Simple Linear Regression\nConsider testing a set of hypotheses for a model of the data generating process of the form (@eq-slr):\n\n$$(\\text{Response})_i = \\beta_0 + \\beta_1(\\text{Predictor})_i + \\varepsilon_i.$$\n\nDenote this model as Model 1, and denote the model that results from applying the parameter constraints defined under the null hypothesis as Model 0[^Fcaveat].  A standardized statistic, sometimes called the \"standardized F statistic,\" for testing the hypotheses is given by\n\n$$T^* = \\frac{\\left(SSE_0 - SSE_1\\right) / (2 - r)}{SSE_1 / (n - 2)},$$\n\nwhere $r$ is the number of parameters in the reduced model.  Defining \n\n$$MSA = \\frac{SSE_0 - SSE_1}{2 - r}$$\n\nto be the \"mean square for additional terms,\" which captures the shift in the error sum of squares from the reduced model to the full unconstrained model, we can write the standardized statistic as\n\n$$T^* = \\frac{MSA}{MSE}$$\n\nwhere the mean square error in the denominator comes from the full unconstrained model.\n:::\n\nIt can be shown that this standardized statistic is a generalization of the one introduced in @sec-teststat.  The numerator captures the signal by examining the difference between what we expect the error sum of squares to be under the null hypothesis and what we actually observe; the denominator captures the background noise (relative to the estimated mean response from the full model).  Larger values of this standardized statistic indicate more evidence in the sample against the null hypothesis.\n\nWe should not lose sight of the fact that our standardized statistic is really a result of partitioning the variability and considering the variability explained by the predictor relative to the noise in the response.  Underscoring that the standardized statistic is a result of this partitioning, the analyses of these sources of variability is often summarized in a table similar to that represented in @fig-regquality-ANOVA-table.\n\n```{r}\n#| label: fig-regquality-ANOVA-table\n#| fig-cap: Table summarizing the partitioning of variability in a regression model.\n#| fig-alt: A table with three rows; the first captures the degrees of freedom, sum of squares, and mean square associated with the predictor.  The second captures the degrees of freedom, sum of squares, and mean square associated with the error.  These are the components necessary for computing a standardized statistic.\nknitr::include_graphics(\"./images/RegQuality-ANOVA-Table.jpg\")\n```\n\nThe last entry in the table is the p-value.  As with any p-value, it is computed by finding the likelihood, assuming the null hypothesis is true, of obtaining a standardized statistic, by chance alone, as extreme or more so than that observed in our sample.  \"More extreme\" values of the statistic would be larger values; so, the area to the right in the model for the null distribution is needed.  The key step is modeling that null distribution.  This is where the conditions we place on the error term that were discussed in @sec-regconditions come into play.  Under the classical regression conditions, we can model the null distribution analytically (see @sec-app-theory); otherwise, we can rely on bootstrapping to model the null distribution.\n\nLet's return to our question that inspired our investigation:\n\n  > Is there evidence the average bracketed duration for a location following an earthquake is linearly related to the distance the location is from the center of the earthquake?\n  \nThis corresponds to testing the hypotheses\n\n$$H_0: \\beta_1 = 0 \\qquad \\text{vs.} \\qquad H_1: \\beta_1 \\neq 0.$$\n\n@tbl-regquality-anova gives the table summarizing the partitioned sources of variability in the bracketed duration.  We have a large p-value (computed assuming the data is consistent with the classical regression model).  That is, the sample provides no evidence to suggest that locations further from the center of the earthquake experience a bracketed duration which differs, on average, from those closer to the center of the earthquake.\n\n```{r}\n#| label: tbl-regquality-anova\n#| tbl-cap: Analysis of the sources of variability in the bracketed duration as a function of epicentral distance.\n\nfit.greece.slr2 |>\n  compare_models(\n    reduced.mean.model = lm(BD02 ~ 1, data = greece.df),\n    assume.constant.variance = TRUE,\n    assume.normality = TRUE\n  ) |>\n  mutate(p.value = ifelse(p.value>=0.001, round(p.value, 3), \"< 0.001\")) |>\n  select(Term = source,\n         DF = df,\n         `Sum of Squares` = ss,\n         `Mean Square` = ms,\n         `Standardized Statistic` = standardized.statistic,\n         `P-Value` = p.value) |>\n  mutate(Term = recode(Term, \n                       \"Additional Terms\" = \"Epicentral Distance\")) |>\n  mykable(digits = 3) |>\n  kableExtra::kable_styling(\n    latex_options = c('striped', 'scale_down')\n  )\n```\n\n:::{.callout-tip}\n## Big Idea\nDetermining if a response is linearly related to a predictor is done by determining if the predictor explains a significant portion of the variability in the response.\n:::\n\nIn this section, we partitioned variability as a way of evaluating the strength of evidence the predictor plays in determining the response.  In the previous section, we used that same partition to quantify the predictive ability of the model for the data generating process.  Regardless of our goal, conducting inference or predicting a future response, partitioning the variability is a key step.  If inference is our primary aim, this partitioning allows us to determine if a predictor adds to the model above and beyond the error alone.  If prediction is our primary aim, the partitioning allows us to quantify the quality of the model's predictive ability.\n\n[^Fcaveat]: Technically, this standardized statistic only applies to a class of potential hypotheses, but that class is quite broad (see @sec-app-teststat).\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["mystyles.css"],"output-file":"03h-regquality.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","bibliography":["refs223notes.bib","packages.bib"],"comments":{"hypothesis":false},"fig-cap-location":"bottom","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":true,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"03h-regquality.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["refs223notes.bib","packages.bib"],"comments":{"hypothesis":false},"fig-cap-location":"bottom","documentclass":"scrreprt"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}