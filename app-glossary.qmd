# Glossary

{{< include _setupcode.qmd >}}

## Five Fundamental Ideas of Inference
This text revolves around five fundamental ideas of inference.  These were introduced in the text, and they are provided here for quick reference along with a link to where they were first introduced.

:::{.callout-important}
## Fundamental Idea I (@sec-questions)
A research question can often be framed in terms of a parameter that characterizes the population.  Framing the question should then guide our analysis.
:::

:::{.callout-important}
## Fundamental Idea II (@sec-data)
If data is to be useful for making conclusions about the population, a process referred to as drawing inference, proper data collection is crucial.  Randomization can play an important role ensuring a sample is representative and that inferential conclusions are appropriate.
:::

:::{.callout-important}
## Fundamental Idea III (@sec-summaries)
The use of data for decision making requires that the data be summarized and presented in ways that address the question of interest and represent the variability present.
:::

:::{.callout-important}
## Fundamental Idea IV (@sec-samplingdistns)
Variability is inherent in any process, and as a result, our estimates are subject to sampling variability.  However, these estimates often vary across samples in a predictable way; that is, they have a distribution that can be modeled.
:::

:::{.callout-important}
## Fundamental Idea V (@sec-nulldistns)
With a model for the distribution of a statistic under a proposed model, we can quantify the the likelihood of an observed sample under that proposed model.  This allows us to draw conclusions about the corresponding parameter, and therefore the population, of interest.
:::


## Distributional Quartet
This text refers to what we call the "distributional quartet" --- the four key distributions that are central to nearly any analysis.  These are introduced early in the text and are 

  - The distribution of the population; this characterizes the pattern of variability of a variable across individual units in the population.  While this is not directly observed, we sometimes posit a model for this distribution.
  - The distribution of the sample; this characterizes the pattern of variability of a variable across individual units in the sample.  This is what we summarize (graphically/numerically) using the available data.
  - The sampling distribution of the statistic; this characterizes the pattern of variability of a statistic across repeated samples.  While this is not directly observed, we model it by applying conditions on the stochastic portion of the model for the data generating process.
  - The null distribution of a (often standardized) statistic; this is the sampling distribution of a statistic when a specified null hypothesis is enforced. 



## Models for the Data Generating Process
This text takes a modeling approach to inference.  The following models are introduced in the text; each model is presented with a link to where the model was fully defined in the text.

:::{.callout-important}
## Data Generating Process for Single Mean Response (@eq-single-mean)
In general, given a quantitative response variable and no predictors, our model for the data generating process is

$$(\text{Response})_i = \mu + \epsilon_i$$
  
where $\mu$ represents the average response in the population, the parameter of interest.
:::

:::{.callout-important}
## Simple Linear Regression Model (@eq-slr)
For a quantitative response and a quantitative predictor, the general form of the simple linear regression model is

$$(\text{Response})_i = \beta_0 + \beta_1 (\text{Predictor})_i + \varepsilon_i$$

where $\beta_0$ and $\beta_1$ are parameters governing the model for the data generating process.
:::


:::{.callout-important}
## General Linear Regression Model (@eq-mlr)
For a quantitative response and one or more predictors, the general form of the linear regression model is

$$
\begin{aligned}
  (\text{Response})_i 
    &= \beta_0 + \beta_1 (\text{Predictor 1})_i + \beta_2(\text{Predictor 2})_i + \dotsb + \beta_p (\text{Predictor } p)_i + \varepsilon_i \\
    &= \beta_0 + \sum_{j=1}^{p} \beta_j (\text{Predictor j})_i + \varepsilon_i
\end{aligned}
$$

where $\beta_j$ for $j = 0, 1, 2, \dotsc, p$ are the $p + 1$ parameters governing the model for the data generating process.
:::


:::{.callout-important}
## ANOVA Model (@eq-anova)
For a quantitative response and a single categorical predictor (also known as a factor) with $k$ levels, the ANOVA model is

$$(\text{Response})_i = \sum_{j = 1}^{k} \mu_j (\text{Group } j)_i + \varepsilon_i$$

where

$$(\text{Group } j)_i = \begin{cases} 1 & \text{i-th unit belongs to group } j \\ 0 & \text{otherwise} \end{cases}$$

is an indicator variable capturing whether a unit belongs to the $j$-th group and $\mu_1, \mu_2, \dotsc, \mu_k$ are the parameters governing the model for the data generating process.
:::


:::{.callout-important}
## Repeated Measures ANOVA Model (@eq-blocks)
For a quantitative response and a single categorical predictor (also known as a factor) with $k$ levels in the presence of $b$ blocks, the repeated measures ANOVA model is

$$(\text{Response})_i = \sum_{j = 1}^{k} \mu_j (\text{Group } j)_i + \sum_{m = 2}^{b} \beta_m (\text{Block } m)_i + \varepsilon_i$$ 

where

$$
\begin{aligned}
  (\text{Group } j)_i 
    &= \begin{cases} 1 & \text{i-th unit belongs to group } j \\ 0 & \text{otherwise} \end{cases} \\
  (\text{Block } m)_i 
    &= \begin{cases} 1 & \text{i-th unit belongs to block } m \\ 0 & \text{otherwise} \end{cases}
\end{aligned}
$$ 

are indicator variables capturing whether a unit belongs to the $j$-th group and $m$-th block, respectively; and, $\mu_1, \mu_2, \dotsc, \mu_k$ and $\beta_2, \beta_3, \dotsc, \beta_b$ are the parameters governing the model for the data generating process.

This model assumes any differences between groups are similar across all blocks.
:::


## Glossary
The following key terms were defined in the text; each term is presented with a link to where the term was first encountered in the text.

```{r}
#| label: create-glossary
#| output: asis

# Create a list of definitions from a QMD file.
determine_terms <- function(x) {
  defns <- repeat_block(x, pattern = ':::\\{#def-')
  
  tibble(
    labels = get_terms(defns, 'reference'),
    terms = get_terms(defns, 'title'),
    defn = str_trim(get_terms(defns, 'text'))
  )
}


# Obtain definitions from all files
defns <- list.files() |>
  str_subset(pattern = fixed('.qmd')) |>
  str_subset(pattern = 'glossary', negate = TRUE) |>
  map(~ determine_terms(read_lines(.x))) |>
  list_rbind() |>
  arrange(terms)


# Create readable table
for (i in 1:nrow(defns)) {
  cat(defns$terms[i], ' (@', defns$labels[i], ') \n',
      ': ', defns$defn[i], '\n\n', sep = '')
}
```

